# frozen_string_literal: true

# Auto-generated by json-schema-llm â€” do not edit.
# Component: {{ component_name }}

require "json"

module {{ generator_module }}
  module {{ module_name }}
    SCHEMA_PATH = File.join(__dir__, "schemas", "{{ schema_path }}")
    CODEC_PATH  = File.join(__dir__, "schemas", "{{ codec_path }}")
    ORIGINAL_PATH = File.join(__dir__, "schemas", "{{ original_path }}")

    # Load the LLM-compatible schema for {{ component_name }}.
    # Note: Schemas are memoized at the module level.
    # @return [Hash] the parsed JSON schema
    def self.schema
      @schema ||= JSON.parse(File.read(SCHEMA_PATH))
    end

    # Load the rehydration codec for {{ component_name }}.
    # @return [Hash] the parsed codec
    def self.codec
      @codec ||= JSON.parse(File.read(CODEC_PATH))
    end

    # Load the original JSON Schema for {{ component_name }}.
    # @return [Hash] the parsed original schema
    def self.original
      @original ||= JSON.parse(File.read(ORIGINAL_PATH))
    end

    # Run a full LLM roundtrip for {{ component_name }} using pre-built artifacts.
    #
    # @param prompt [String] the natural language prompt
    # @param engine [JsonSchemaLlmEngine::LlmRoundtripEngine] the roundtrip engine
    # @return [JsonSchemaLlmEngine::RoundtripResult]
    def self.generate(prompt, engine)
      engine.generate_with_preconverted(
        original_schema_json: JSON.generate(original),
        codec_json: JSON.generate(codec),
        llm_schema: schema,
        prompt: prompt
      )
    end
  end
end
