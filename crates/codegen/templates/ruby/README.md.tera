# {{ sdk_name }}

Auto-generated Ruby SDK for json-schema-llm schemas.

## Installation

Add to your Gemfile:

```ruby
gem "{{ sdk_name }}"
```

Then run:

```bash
bundle install
```

## Usage

```ruby
require "{{ module_name }}"
require "json_schema_llm_engine"

# Create the engine with your provider configuration
engine = JsonSchemaLlmEngine::LlmRoundtripEngine.new(
  formatter: JsonSchemaLlmEngine::Formatters::ChatCompletions.new,
  config: JsonSchemaLlmEngine::ProviderConfig.new(
    url: "https://api.openai.com/v1/chat/completions",
    model: "gpt-4o",
    headers: { "Authorization" => "Bearer #{ENV["OPENAI_API_KEY"]}" }
  ),
  transport: my_transport
)

# Generate using a pre-built component
{% for component in components %}result = {{ generator_module }}::{{ component.module_name }}.generate("{{ component.description }}", engine)
{% endfor %}
```

## Components

{% for component in components %}
### {{ component.name }}

```ruby
{{ generator_module }}::{{ component.module_name }}.schema    # LLM-compatible schema
{{ generator_module }}::{{ component.module_name }}.codec     # Rehydration codec
{{ generator_module }}::{{ component.module_name }}.original  # Original JSON Schema
{{ generator_module }}::{{ component.module_name }}.generate(prompt, engine)  # Full roundtrip
```
{% endfor %}

## License

Generated by [json-schema-llm](https://github.com/dotslashderek/jsonschema-llm).
