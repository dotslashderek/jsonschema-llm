<p align="center">
  <h1 align="center">jsonschema-llm</h1>
  <p align="center">
    Convert any JSON Schema into an LLM-compatible structured output schema.<br/>
    Full round-trip: <strong>Schema â†’ Convert â†’ Generate â†’ Rehydrate â†’ Original Shape</strong>
  </p>
  <p align="center">
    <a href="https://github.com/dotslashderek/jsonschema-llm/releases"><img src="https://img.shields.io/badge/status-alpha-orange" alt="Status: Alpha"></a>
    <a href="COMPATIBILITY.md"><img src="https://img.shields.io/badge/compatibility-matrix-blue" alt="Compatibility Matrix"></a>
  </p>
</p>

<p align="center">
  <a href="#quick-start">Quick Start</a> â€¢
  <a href="#why">Why</a> â€¢
  <a href="#usage">Usage</a> â€¢
  <a href="#algorithm">Algorithm</a> â€¢
  <a href="#rehydration">Rehydration</a> â€¢
  <a href="#providers">Provider Support</a> â€¢
  <a href="ROADMAP.md">Roadmap</a>
</p>

---

## The Problem

You have a JSON Schema. You want an LLM to generate data that conforms to it. But LLM providers only support a **subset** of JSON Schema â€” and each provider supports a _different_ subset.

| Feature                       | Your Schema | OpenAI Strict | Gemini | Claude |
| ----------------------------- | :---------: | :-----------: | :----: | :----: |
| `$ref`                        |     âœ…      |      âŒ       |   âœ…   |   âŒ   |
| `oneOf` / `allOf`             |     âœ…      |      âŒ       |   âš ï¸   |   âŒ   |
| `additionalProperties` (maps) |     âœ…      |      âŒ       |   âœ…   |   âŒ   |
| Recursive schemas             |     âœ…      |      âŒ       |   âœ…   |   âš ï¸   |
| `minimum` / `maximum`         |     âœ…      |      âŒ       |   âœ…   |   âŒ   |
| Open-ended `{type: object}`   |     âœ…      |      âŒ       |   âš ï¸   |   âŒ   |

You're left hand-converting schemas, losing information, and writing custom parsing code for every project.

## The Solution

`jsonschema-llm` is a **schema-to-schema compiler**. Feed it any JSON Schema (Draft 2020-12 or earlier) and it produces:

1. **A converted schema** â€” the most faithful LLM-compatible projection possible
2. **A codec** â€” rehydration metadata to reconstruct the original shape from LLM output

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Your Schema  â”‚â”€â”€â”€â”€â–¶â”‚ jsonschema-  â”‚â”€â”€â”€â”€â–¶â”‚  LLM    â”‚â”€â”€â”€â”€â–¶â”‚  Rehydrator  â”‚â”€â”€â”€â”€â–¶â”‚ Original     â”‚
â”‚ (full)       â”‚     â”‚ llm convert  â”‚     â”‚ (any)   â”‚     â”‚  + codec     â”‚     â”‚ Shape        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                      â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
                      â”‚  Codec    â”‚
                      â”‚ (sidecar) â”‚
                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

This is a standalone, deterministic transformer.

---

## Quick Start

### CLI

```bash
# Install
cargo install jsonschema-llm

# Convert a schema for OpenAI Strict (default)
jsonschema-llm convert schema.json -o schema.llm.json --codec codec.json

# Convert for Gemini (relaxed â€” preserves more features)
jsonschema-llm convert schema.json -o schema.llm.json --target gemini

# Convert in permissive mode (skip strict enforcement)
jsonschema-llm convert schema.json -o schema.llm.json --mode permissive

# Rehydrate LLM output back to the original shape (pass original schema for type coercion)
jsonschema-llm rehydrate output.json --codec codec.json --schema schema.json
```

### Library

<details>
<summary><strong>TypeScript / JavaScript</strong></summary>

```typescript
import { convert, rehydrate } from "jsonschema-llm";

// Convert
const { schema, codec } = convert(mySchema, { target: "openai-strict" });

// Send to OpenAI
const response = await openai.chat.completions.create({
  model: "gpt-4o",
  response_format: {
    type: "json_schema",
    json_schema: { name: "my_schema", schema, strict: true },
  },
  messages: [{ role: "user", content: prompt }],
});

// Rehydrate â€” maps restored, nulls stripped, JSON strings parsed, types coerced
const original = rehydrate(
  JSON.parse(response.choices[0].message.content),
  codec,
  mySchema,
);
```

</details>

<details>
<summary><strong>Python</strong></summary>

```python
from jsonschema_llm import convert, rehydrate

# Convert
result = convert(my_schema, {"target": "openai-strict"})

# Send to OpenAI
response = client.chat.completions.create(
    model="gpt-4o",
    response_format={"type": "json_schema", "json_schema": {"name": "my_schema", "schema": result["schema"], "strict": True}},
    messages=[{"role": "user", "content": prompt}]
)

# Rehydrate â€” maps restored, nulls stripped, JSON strings parsed, types coerced
import json
rehydrated = rehydrate(json.loads(response.choices[0].message.content), result["codec"], my_schema)
original = rehydrated["data"]
```

</details>

<details>
<summary><strong>Java</strong></summary>

```java
import dev.jsonschema.llm.SchemaConverter;
import dev.jsonschema.llm.Rehydrator;

// Convert
var result = SchemaConverter.convert(schema, Target.OPENAI_STRICT);
var convertedSchema = result.schema();
var codec = result.codec();

// ... send convertedSchema to your LLM provider ...

// Rehydrate (pass original schema for type coercion)
var original = Rehydrator.rehydrate(llmOutput, codec, schema);
```

</details>

---

<a id="why"></a>

## Why This Exists

### The Structured Output Gap

Every major LLM provider now supports structured output â€” the ability to constrain generation to conform to a JSON Schema. This is transformative for code generation, data extraction, API integration, and agent tool use.

But there's a catch: **each provider only supports a subset of JSON Schema**, and the subsets are different. OpenAI is the most restrictive (no `$ref`, no `oneOf`, no `allOf`, no maps, no recursion). Gemini is more relaxed. Claude sits somewhere in between.

If your schema uses any of these features â€” and most real-world schemas do â€” you can't use structured output directly. You have to manually convert your schema, losing information in the process, and then manually parse the output back.

### Real-World Validation

This algorithm was validated against production-scale JSON Schema definitions including the **OpenAPI 3.1 Specification Schema** â€” a complex, real-world schema with:

- Discriminated unions (`oneOf` + `discriminator`)
- Maps everywhere (`additionalProperties` patterns for dynamic key-value structures)
- Opaque plugin configurations (`{type: object}` with no properties, `{}` catch-all schemas)
- `allOf` inheritance across multiple definition layers
- Recursive references

The converted schemas were accepted by **OpenAI Strict Mode**. The LLM generated valid, structured output. The rehydrator reconstructed the original shape. Full round-trip, zero manual intervention.

---

<a id="algorithm"></a>

## Algorithm: The 9-Pass Compiler Pipeline

`jsonschema-llm` transforms schemas through 9 ordered passes, each handling a specific incompatibility. The passes are **ordered** (each assumes previous output), **deterministic**, **provider-aware** (passes are skipped/relaxed per target), **mode-aware** (strict vs permissive), and **metadata-preserving** (every lossy change records how to reverse it).

> ğŸ“– **Full specification with examples, merge rules, and design decisions:** [docs/algorithm.md](docs/algorithm.md)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Input Schema   â”‚  (JSON Schema Draft 2020-12)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Pass 0: Normalization        â”‚  âœ… Resolve $ref, normalize drafts
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ Pass 1: Composition          â”‚  âœ… Merge allOf into flat objects
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ Pass 2: Polymorphism         â”‚  âœ… oneOf â†’ anyOf
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ Pass 3: Dictionary           â”‚  âœ… Map<K,V> â†’ Array<{key, value}>
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ Pass 4: Opaque Types         â”‚  âœ… {type: object} / {} â†’ {type: string}
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ Pass 5: Recursion            â”‚  âœ… Inline all $ref, break cycles
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ Pass 6: Strict Enforcement   â”‚  âœ… additionalProperties: false, all required
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ Pass 7: Constraint Pruning   â”‚  âœ… Drop unsupported constraints
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ Pass 9: Provider Compat      â”‚  âœ… Pre-flight provider validation
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Converted Schema â”‚   â”‚   Codec   â”‚
    â”‚ (LLM-compatible) â”‚   â”‚ (sidecar) â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Pass Summaries

| Pass  | Name               | What It Does                                                                                                                                                                                                     | Lossy?                       |
| ----- | ------------------ | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------- |
| **0** | Normalization      | Resolves all `$ref` pointers to inline definitions, normalizes syntax across draft versions (e.g. `items` array â†’ `prefixItems`), and detects recursive cycles for later handling.                               | No                           |
| **1** | Composition        | Merges `allOf` sub-schemas into a single flat object â€” the common "inheritance" pattern. Properties are unioned, required arrays are unioned, conflicting types are intersected.                                 | Partially                    |
| **2** | Polymorphism       | Rewrites `oneOf` â†’ `anyOf`. OpenAI/Claude can't enforce "exactly one matches" during generation; `anyOf` is functionally equivalent and universally supported. Preserves `discriminator` for variant selection.  | No                           |
| **3** | Dictionary         | Converts `Map<String, T>` patterns (`additionalProperties: T`) into arrays of `{key, value}` items. OpenAI requires `additionalProperties: false` on every object. _Skipped for Gemini._                         | Yes â€” reversed by rehydrator |
| **4** | Opaque Types       | Converts open-ended schemas (`{type: object}` with no properties, `{}`) into `{type: string}` with instructions to produce JSON-encoded strings.                                                                 | Data preserved, UX degraded  |
| **5** | Recursion          | Inlines all remaining `$ref` pointers and breaks recursive cycles at a configurable depth limit (default 3) using dynamic per-branch cycle detection. Strips `$defs` after resolution. _Skipped for Gemini._     | Depth capped                 |
| **6** | Strict Enforcement | Sets `additionalProperties: false`, moves all properties to `required`, and wraps originally-optional properties in `anyOf: [T, {type: null}]`. The "gatekeeper" pass for OpenAI Strict.                         | No                           |
| **7** | Constraint Pruning | Removes unsupported validation keywords per target (e.g. `minimum`, `maxLength`, `format`), normalizes `const` â†’ `enum`, and sorts enum values to put `default` first. Records dropped constraints in the codec. | Validation-only data lost    |
| **9** | Provider Compat    | Pre-flight checks for target-specific constraints (e.g. root must be object, depth budget, enum homogeneity). Returns soft errors â€” schema is still produced.                                                    | No (read-only)               |

---

<a id="rehydration"></a>

## Rehydration

The codec sidecar file contains enough information to reconstruct the original data shape from LLM output:

| Codec Type           | Forward (Convert)                              | Reverse (Rehydrate)                 |
| -------------------- | ---------------------------------------------- | ----------------------------------- |
| `map_to_array`       | `{a: 1, b: 2}` â†’ `[{key: "a", value: 1}, ...]` | `[{key: "a", value: 1}]` â†’ `{a: 1}` |
| `json_string_parse`  | `{config: {...}}` â†’ `{config: "{...}"}`        | `"{...}"` â†’ `{...}`                 |
| `recursive_inflate`  | Recursive ref â†’ `"{...}"` at depth limit       | `"{...}"` â†’ `{...}` (same as above) |
| `nullable_optional`  | Required field, optional â†’ nullable            | If `null`, remove key entirely      |
| `dropped_constraint` | `minLength: 1` â†’ removed                       | Post-generation validation          |

```python
# Full round-trip example
from jsonschema_llm import convert, rehydrate

result = convert(my_api_schema)
llm_output = call_openai(result["schema"], prompt)

# LLM output has arrays where you had maps, strings where you had objects, nulls everywhere
# Rehydrate fixes all of it:
rehydrated = rehydrate(llm_output, result["codec"], my_api_schema)

# rehydrated["data"] now has:
# - Maps restored: {"X-Rate-Limit": "100"} instead of [{key: "X-Rate-Limit", value: "100"}]
# - Nulls stripped: optional fields that were null are removed entirely
# - JSON strings parsed: plugin configs are proper objects again
```

---

<a id="providers"></a>

## Provider Target Matrix

| Feature                        | OpenAI Strict |      Gemini      |      Claude      |
| ------------------------------ | :-----------: | :--------------: | :--------------: |
| `additionalProperties: false`  |   Required    |     Optional     |   Recommended    |
| All props `required`           |   Required    |     Optional     |   Recommended    |
| `anyOf`                        |      âœ…       |        âœ…        |        âœ…        |
| `oneOf`                        | âŒ â†’ `anyOf`  | âœ… (skip Pass 2) |   âš ï¸ â†’ `anyOf`   |
| `allOf`                        |  âŒ â†’ merge   |    âš ï¸ â†’ merge    |    âŒ â†’ merge    |
| Recursive `$ref`               |  âŒ â†’ break   | âœ… (skip Pass 5) | âš ï¸ â†’ limit depth |
| `additionalProperties: Schema` |  âŒ â†’ array   | âœ… (skip Pass 3) |    âŒ â†’ array    |
| `{type: object}` (opaque)      |  âŒ â†’ string  |   âš ï¸ â†’ string    |   âŒ â†’ string    |
| `minimum` / `maximum`          |   âŒ â†’ drop   |  âœ… (preserve)   |    âŒ â†’ drop     |
| `pattern`                      |      âœ…       |        âœ…        |    âŒ â†’ drop     |

---

## Known Limitations

1. **Recursion**: Recursive schemas are supported up to a configurable depth (default: 3). Deeply nested recursive structures may be truncated.
2. **Mixed-Type Arrays**: Arrays with mixed types (e.g. `[1, "string"]`) may have reduced fidelity in some LLM providers.
3. **Opaque Objects**: Schemas using `type: "object"` without properties are converted to JSON strings to avoid hallucination, requiring rehydration to restore.
4. **Provider Variations**: While OpenAI Strict is fully validated, other providers (Gemini, Claude) have varying degrees of structured output support. The `COMPATIBILITY.md` file tracks granular feature support.

---

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              jsonschema-llm-core             â”‚
â”‚                 (Rust crate)                  â”‚
â”‚                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Converterâ”‚  â”‚  Codec   â”‚  â”‚Rehydrator â”‚  â”‚
â”‚  â”‚ (9 pass) â”‚  â”‚ Builder  â”‚  â”‚           â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚          â”‚                      â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â” â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â” â”Œâ–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CLI  â”‚ â”‚TypeScriptâ”‚ â”‚  Python  â”‚ â”‚  Java   â”‚
â”‚(Rust) â”‚ â”‚  (WASM)  â”‚ â”‚  (PyO3)  â”‚ â”‚(JNI/FFI)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

The core library is written in **Rust** using `serde_json::Value` for schema manipulation with recursive descent transformers. Language bindings are shipped as separate crates: [TypeScript via WASM](https://github.com/dotslashderek/jsonschema-llm/issues/38) (âœ… shipped), [Python via PyO3](https://github.com/dotslashderek/jsonschema-llm/issues/39) (âœ… shipped), and [Java via JNI](https://github.com/dotslashderek/jsonschema-llm/issues/40) (planned).

---

## Project Status

### v0.1 â€” Core Pipeline âœ…

The 9-pass compiler pipeline, rehydrator, codec, and CLI are all implemented and green.

| Component              | Status      | Notes                                                   |
| ---------------------- | ----------- | ------------------------------------------------------- |
| Pass 0: Normalization  | âœ… Complete | `$ref` resolution, cycle detection, draft normalization |
| Pass 1: Composition    | âœ… Complete | `allOf` merge with property/required union              |
| Pass 2: Polymorphism   | âœ… Complete | `oneOf` â†’ `anyOf` rewrite                               |
| Pass 3: Dictionary     | âœ… Complete | Map â†’ Array transpilation with codec                    |
| Pass 4: Opaque Types   | âœ… Complete | Stringification with codec                              |
| Pass 5: Recursion      | âœ… Complete | Dynamic cycle detection, configurable depth limit       |
| Pass 6: Strict Mode    | âœ… Complete | `additionalProperties: false`, nullable optionals       |
| Pass 7: Constraints    | âœ… Complete | Constraint pruning, enum sorting, constâ†’enum            |
| Rehydrator             | âœ… Complete | Full reverse transforms with advisory warnings          |
| Pipeline (`convert()`) | âœ… Complete | Wires all 9 passes with codec accumulation              |
| CLI                    | âœ… Complete | `convert` and `rehydrate` subcommands via `clap`        |

Validated against production-grade schemas including the OpenAPI 3.1 Specification Schema. All accepted by OpenAI Strict Mode with full round-trip rehydration.

### v0.2 â€” Roadmap

See **[ROADMAP.md](ROADMAP.md)** for the full prioritized roadmap with epic progress, bucket breakdown, and execution order.

| Epic                                                                                | Status         | Progress | Description                                                                |
| ----------------------------------------------------------------------------------- | -------------- | :------: | -------------------------------------------------------------------------- |
| [Core Improvements](https://github.com/dotslashderek/jsonschema-llm/issues/36)      | ğŸŸ¡ Active      |   75%    | Walker unification, rehydrator decomposition, test hardening, docs cleanup |
| [FFI Facade](https://github.com/dotslashderek/jsonschema-llm/issues/37)             | âœ… Complete    |   100%   | JSON-string bridge API, stable error codes, serde-ready types              |
| [TypeScript / JS (WASM)](https://github.com/dotslashderek/jsonschema-llm/issues/38) | âœ… Complete    |   100%   | `wasm-pack` + `serde-wasm-bindgen`, npm package                            |
| [Python (PyO3)](https://github.com/dotslashderek/jsonschema-llm/issues/39)          | âœ… Complete    |   100%   | `maturin` + `pythonize`, PyPI package                                      |
| [Java (JNI)](https://github.com/dotslashderek/jsonschema-llm/issues/40)             | â¬œ Not started |    0%    | `jni-rs` + JSON string bridge, Maven Central                               |
| [Conformance Suite](https://github.com/dotslashderek/jsonschema-llm/issues/76)      | â¬œ Not started |    0%    | Provider-specific test suites, OpenAPI/AsyncAPI support                    |
| [Test Harness](https://github.com/dotslashderek/jsonschema-llm/issues/115)          | â¬œ Not started |    0%    | Retry logic, known-fail classification, regression tracking                |

---

## License

[Apache License 2.0](LICENSE)

---

## Contributing

See [CONTRIBUTING.md](CONTRIBUTING.md) for development setup and guidelines.
